---
---
@inproceedings{moradi2021Measuring,
  abbr="EACL",
  title={Measuring and Improving Faithfulness of Attention in Neural Machine Translation},
  author={Moradi, Pooya and Kambhatla, Nishant and Sarkar, Anoop},
  booktitle={(To Appear) Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL): Long Papers},
  year={2021}
}

@inproceedings{moradi-etal-2020-training,
    abbr="AACL SRW",
    title = {Training with Adversaries to Improve Faithfulness of Attention in Neural Machine Translation},
    author = "Moradi, Pooya  and
      Kambhatla, Nishant  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.aacl-srw.14",
    pages = "93--100",
    abstract = "Can we trust that the attention heatmaps produced by a neural machine translation (NMT) model reflect its true internal reasoning? We isolate and examine in detail the notion of faithfulness in NMT models. We provide a measure of faithfulness for NMT based on a variety of stress tests where model parameters are perturbed and measuring faithfulness based on how often the model output changes. We show that our proposed faithfulness measure for NMT models can be improved using a novel differentiable objective that rewards faithful behaviour by the model through probability divergence. Our experimental results on multiple language pairs show that our objective function is effective in increasing faithfulness and can lead to a useful analysis of NMT model behaviour and more trustworthy attention heatmaps. Our proposed objective improves faithfulness without reducing the translation quality and it also seems to have a useful regularization effect on the NMT model and can even improve translation quality in some cases.",
}

@article{born-etal-2019-sign,
    abbr="NAACL WS",
    title = {Sign Clustering and Topic Extraction in Proto-Elamite},
    author = {Born, Logan  and
      Kelley, Kate  and
      Kambhatla, Nishant  and
      Chen, Carolyn  and
      Sarkar, Anoop},
    journal = {Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature @ NAACL},
    month = jun,
    year = {2019},
    address = {Minneapolis, USA},
    publisher = {Association for Computational Linguistics},
    url = {https://www.aclweb.org/anthology/W19-2516},
    abstract={We describe a first attempt at using techniques from computational linguistics to analyze the undeciphered proto-Elamite script. Using hierarchical clustering, n-gram frequencies, and LDA topic models, we both replicate results obtained by manual decipherment and reveal previously-unobserved relationships between signs. This demonstrates the utility of these techniques as an aid to manual decipherment.}
}

@article{moradi2019interrogating,
  abbr={EMNLP WS},
  title={Interrogating the Explanatory Power of Attention in Neural Machine Translation},
  author={Moradi, Pooya and Kambhatla, Nishant and Sarkar, Anoop},
  journal={The 3rd Workshop on Neural Generation and Translation @ EMNLP-IJCNLP},
  pages={221},
  year={2019},
  url={https://www.aclweb.org/anthology/D19-5624.pdf},
  abstract={Attention models have become a crucial component in neural machine translation (NMT). They are often implicitly or explicitly used to justify the model{'}s decision in generating a specific token but it has not yet been rigorously established to what extent attention is a reliable source of information in NMT. To evaluate the explanatory power of attention for NMT, we examine the possibility of yielding the same prediction but with counterfactual attention models that modify crucial aspects of the trained attention model. Using these counterfactual attention mechanisms we assess the extent to which they still preserve the generation of function and content words in the translation process. Compared to a state of the art attention model, our counterfactual attention models produce 68{\%} of function words and 21{\%} of content words in our German-English dataset. Our experiments demonstrate that attention models by themselves cannot reliably explain the decisions made by a NMT model.}
}

@inproceedings{kambhatla-etal-2018-decipherment,
    abbr = "EMNLP",
    title = "Decipherment of Substitution Ciphers with Neural Language Models",
    author = "Kambhatla, Nishant  and
      Mansouri Bigvand, Anahita  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1102",
    doi = "10.18653/v1/D18-1102",
    pages = "869--874",
    abstract = "Decipherment of homophonic substitution ciphers using language models is a well-studied task in NLP. Previous work in this topic scores short local spans of possible plaintext decipherments using n-gram language models. The most widely used technique is the use of beam search with n-gram language models proposed by Nuhn et al.(2013). We propose a beam search algorithm that scores the entire candidate plaintext at each step of the decipherment using a neural language model. We augment beam search with a novel rest cost estimation that exploits the prediction power of a neural language model. We compare against the state of the art n-gram based methods on many different decipherment tasks. On challenging ciphers such as the Beale cipher we provide significantly better error rates with much smaller beam sizes.",
}

@inproceedings{wu-etal-2018-decipherment,
    abbr= "EMNLP WS",
    title = "Decipherment for Adversarial Offensive Language Detection",
    author = "Wu, Zhelun  and
      Kambhatla, Nishant  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2) @ EMNLP",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5119",
    doi = "10.18653/v1/W18-5119",
    pages = "149--159",
    abstract = "Automated filters are commonly used by online services to stop users from sending age-inappropriate, bullying messages, or asking others to expose personal information. Previous work has focused on rules or classifiers to detect and filter offensive messages, but these are vulnerable to cleverly disguised plaintext and unseen expressions especially in an adversarial setting where the users can repeatedly try to bypass the filter. In this paper, we model the disguised messages as if they are produced by encrypting the original message using an invented cipher. We apply automatic decipherment techniques to decode the disguised malicious text, which can be then filtered using rules or classifiers. We provide experimental results on three different datasets and show that decipherment is an effective tool for this task.",
}
